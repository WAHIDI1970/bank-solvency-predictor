# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yis2FgZRzgOIa1BTB-V124jnob49K7om
"""

# Installer pyreadstat si besoin
!pip install pyreadstat

"""# üìä Pr√©paration des Donn√©es:"""

import pyreadstat
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()

# Charger le fichier .sav
df,meta = pyreadstat.read_sav("/content/scoring.sav")

# Aper√ßu des donn√©es
df.head()

df.describe()

"""#üí† Analyse des Donn√©es :




"""

# Valeurs manquantes
print(df.isnull().sum())

# Distribution des variables num√©riques
df.hist(figsize=(12, 8), bins=20)
plt.suptitle("Histogrammes des variables", fontsize=16)
plt.tight_layout()
plt.show()

# Boxplots
for col in df.select_dtypes(include='number').columns:
    plt.figure()
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot de {col}")
    plt.show()

# Corr√©lation
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Matrice de corr√©lation")
plt.show()

df['Amount'].describe()

df['Statut1'].describe()
nsolva = df[df.Statut1 == 1]
solva = df[df.Statut1 == 0]

nsolva.Amount.describe()

solva.Amount.describe()

"""# ‚úÖ la regression Logistique :"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# S√©paration X / y
X = df.drop(columns='Statut1')
y = df['Statut1']

# D√©coupage train / test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve ,accuracy_score

# Mod√®le
log_model = LogisticRegression(class_weight='balanced', random_state=42)
log_model.fit(X_train_scaled, y_train)

# Pr√©dictions
y_pred_log = log_model.predict(X_test_scaled)

from sklearn.metrics import confusion_matrix
# 1. Calcul de la matrice de confusion
cm = confusion_matrix(y_test, y_pred_log)

# 2. Affichage avec seaborn (graphique am√©lior√©)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Non D√©faillant (0)", "D√©faillant (1)"],
            yticklabels=["Non D√©faillant (0)", "D√©faillant (1)"])
plt.title("Matrice de Confusion")
plt.xlabel("Pr√©dictions")
plt.ylabel("Vraies valeurs")
plt.show()

# √âvaluation
print(confusion_matrix(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))
print("AUC :", roc_auc_score(y_test, log_model.predict_proba(X_test_scaled)[:, 1]))

# ROC
fpr, tpr, _ = roc_curve(y_test, log_model.predict_proba(X_test_scaled)[:, 1])
plt.plot(fpr, tpr)
plt.xlabel("Faux positifs")
plt.ylabel("Vrais positifs")
plt.title("Courbe ROC - R√©gression Logistique")
plt.grid()
plt.show()

print("Nombre total :", len(y_test))
print("Classe 0 dans test :", sum(y_test == 0))
print("Classe 1 dans test :", sum(y_test == 1))

print("Nombre total :", len(y_train))
print("Classe 0 dans test :", sum(y_train == 0))
print("Classe 1 dans test :", sum(y_train == 1))

"""# ‚ùå outliers :"""

def detect_outliers_iqr(data, variable):
    Q1 = data[variable].quantile(0.25)
    Q3 = data[variable].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return ((data[variable] < lower_bound) | (data[variable] > upper_bound))

# Exemple : d√©tection des outliers pour Amount
df['outlier_amount'] = detect_outliers_iqr(df, 'Amount')

# Comptage des outliers par classe
df.groupby('Statut1')['outlier_amount'].sum()

# Fonction de d√©tection des outliers avec IQR
def detect_outliers_iqr(data, variable):
    Q1 = data[variable].quantile(0.25)
    Q3 = data[variable].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return ((data[variable] < lower_bound) | (data[variable] > upper_bound))

# Liste des variables √† tester
variables = ['Amount', 'Expenses', 'Price', 'Income']

# Boucle pour cr√©er une colonne d'outliers pour chaque variable
for var in variables:
    df[f'outlier_{var.lower()}'] = detect_outliers_iqr(df, var)

# Regrouper par Statut1 et compter les outliers
outlier_counts = df.groupby('Statut1')[[f'outlier_{v.lower()}' for v in variables]].sum()

# Afficher les r√©sultats
print(outlier_counts)

df_clean = df[
    ~(df['outlier_amount'] | df['outlier_expenses'] | df['outlier_price'] | df['outlier_income'])
]

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# S√©paration X / y
Xc = df_clean.drop(columns='Statut1')
yc =df_clean['Statut1']

# D√©coupage train / test
Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2, random_state=42)

# Standardisation
scaler = StandardScaler()
Xc_train_scaled = scaler.fit_transform(X_train)
Xc_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve

# Mod√®le
log_modelc= LogisticRegression(class_weight='balanced', random_state=42)
log_modelc.fit(Xc_train_scaled , yc_train)

# Pr√©dictions
yc_pred_log = log_modelc.predict(Xc_test_scaled)

# √âvaluation
print(confusion_matrix(yc_test, yc_pred_log))
print(classification_report(yc_test, yc_pred_log))
print("AUC :", roc_auc_score(yc_test, log_modelc.predict_proba(Xc_test_scaled)[:, 1]))

# ROC
fpr, tpr, _ = roc_curve(yc_test, log_model.predict_proba(Xc_test_scaled)[:, 1])
plt.plot(fpr, tpr)
plt.xlabel("Faux positifs")
plt.ylabel("Vrais positifs")
plt.title("Courbe ROC - R√©gression Logistique")
plt.grid()
plt.show()

import pandas as pd

# Cr√©ation des donn√©es avec les noms exacts des colonnes
data = {
    'Age': [45, 26],
    'Marital': [1, 3],  # Nom corrig√© pour correspondre √† votre demande
    'Expenses': [100, 90],
    'Income': [200, 150],
    'Amount': [800, 650],
    'Price': [1000, 1600]
}

# Conversion en DataFrame
df = pd.DataFrame(data)

# Afficher les donn√©es
print("Base de donn√©es pour le test :")
print(df)


try:
    y_pred_log = log_model.predict(df)
    print("\nPr√©dictions du mod√®le :")
    print(y_pred_log)

    # Optionnel : Afficher les probabilit√©s (si mod√®le de classification)
    if hasattr(log_model, 'predict_proba'):
        y_proba_log = log_model.predict_proba(df)
        print("\nProbabilit√©s estim√©es par classe :")
        print(y_proba_log)
except Exception as e:
    print(f"\nErreur lors de la pr√©diction : {e}")

"""# ‚ûï **KNN :**






"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import ConfusionMatrixDisplay

knn = KNeighborsClassifier(n_neighbors=5, weights='distance')  # n_neighbors √† ajuster
knn.fit(X_train_scaled, y_train)

y_pred = knn.predict(X_test_scaled)

print("üìä Rapport de classification :")
print(classification_report(y_test, y_pred))
# Matrice de confusion
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_)
disp.plot(cmap='Blues')
plt.title("Matrice de Confusion - KNN")
plt.show()

"""# ‚úÖ**meilleur model KNN** :

"""

from sklearn.model_selection import cross_val_score

for k in range(1, 20):
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='f1_macro')
    print(f'k={k}, F1 macro moyen: {scores.mean():.3f}')

# Entra√Ænement du mod√®le KNN
# Choix de k (par exemple k=5)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Pr√©dictions sur l'ensemble de test
y_pred = knn.predict(X_test)

# √âvaluation du mod√®le
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Affichage des r√©sultats
print(f"Accuracy: {accuracy:.2f}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# Hyperparameter tuning : choix du meilleur k
# Exemple d'une recherche de k optimal via validation crois√©e
from sklearn.model_selection import GridSearchCV

# D√©finir une grille de param√®tres pour k
param_grid = {'n_neighbors': np.arange(1, 21)}

# Recherche du meilleur k
grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Affichage du meilleur k
print(f"Meilleur k trouv√© : {grid_search.best_params_['n_neighbors']}")

# Entra√Ænement avec le meilleur k
best_knn = grid_search.best_estimator_
best_knn.fit(X_train, y_train)

# Pr√©dictions avec le meilleur mod√®le
y_pred_best = best_knn.predict(X_test)

# R√©√©valuation avec le meilleur mod√®le
accuracy_best = accuracy_score(y_test, y_pred_best)
print(f"Accuracy avec le meilleur k : {accuracy_best:.2f}")

"""# ‚úÖ**meilleur model KNN** :




"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import (confusion_matrix, classification_report,
                           accuracy_score, precision_score, recall_score,
                           f1_score, roc_auc_score, roc_curve, auc)
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

## 1. S√©paration des donn√©es
# Supposons que df est votre DataFrame d√©j√† pr√©trait√©
# avec X contenant les features et y la target (0=solvable, 1=non solvable)



## 2. Cr√©ation du pipeline KNN
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),  # Gestion des valeurs manquantes
    ('scaler', StandardScaler()),  # Standardisation des features
    ('knn', KNeighborsClassifier())  # Mod√®le KNN
])

## 3. Optimisation des hyperparam√®tres
param_grid = {
    'knn__n_neighbors': range(3, 21, 2),  # Valeurs impaires de 3 √† 19
    'knn__weights': ['uniform', 'distance'],  # Poids uniformes ou bas√©s sur distance
    'knn__p': [1, 2]  # 1: distance de Manhattan, 2: distance euclidienne
}

grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=5,  # 5-fold cross-validation
    scoring='roc_auc',  # M√©trique d'√©valuation
    n_jobs=-1,  # Utilisation de tous les c≈ìurs CPU
    verbose=1
)

print("Recherche des meilleurs hyperparam√®tres en cours...")
grid_search.fit(X_train, y_train)

## 4. Meilleur mod√®le
best_knn = grid_search.best_estimator_
print("\nMeilleurs param√®tres trouv√©s:")
print(grid_search.best_params_)

## 5. √âvaluation du mod√®le
y_pred = best_knn.predict(X_test)
y_pred_proba = best_knn.predict_proba(X_test)[:, 1]  # Probabilit√©s pour la classe 1 (non solvable)

print("\nPerformance sur l'ensemble de test:")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision: {precision_score(y_test, y_pred):.4f}")  # Capacit√© √† ne pas classer solvable comme non solvable
print(f"Recall: {recall_score(y_test, y_pred):.4f}")  # Capacit√© √† d√©tecter tous les non solvables
print(f"F1-score: {f1_score(y_test, y_pred):.4f}")  # Moyenne harmonique de precision et recall
print(f"AUC-ROC: {roc_auc_score(y_test, y_pred_proba):.4f}")  # Performance globale

## 6. Matrice de confusion
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Solvable', 'Non solvable'],
            yticklabels=['Solvable', 'Non solvable'])
plt.title('Matrice de Confusion')
plt.xlabel('Pr√©dit')
plt.ylabel('R√©el')
plt.show()

## 7. Courbe ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Courbe ROC (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de Faux Positifs')
plt.ylabel('Taux de Vrais Positifs')
plt.title('Courbe ROC - Performance du Mod√®le KNN')
plt.legend(loc="lower right")
plt.show()

## 8. Rapport de classification
print("\nRapport de classification d√©taill√©:")
print(classification_report(y_test, y_pred, target_names=['Solvable', 'Non solvable']))

## 9. Validation crois√©e imbriqu√©e pour √©valuer la robustesse
print("\nValidation crois√©e imbriqu√©e en cours...")
nested_scores = cross_val_score(
    grid_search,
    X_train,
    y_train,
    cv=5,
    scoring='roc_auc',
    n_jobs=-1
)
print(f"Scores de validation crois√©e: {nested_scores}")
print(f"Moyenne AUC-ROC: {nested_scores.mean():.4f} (¬±{nested_scores.std():.4f})")

## 10. Sauvegarde du mod√®le
joblib.dump(best_knn, 'meilleur_modele_knn.joblib')
print("\nMod√®le sauvegard√© sous 'meilleur_modele_knn.joblib'")

## 11. Exemple de pr√©diction
exemple_client = X_train.iloc[0:1].copy()  # Prend le premier client du training set
prediction = best_knn.predict(exemple_client)
probabilite = best_knn.predict_proba(exemple_client)

print("\nExemple de pr√©diction pour un client:")
print(f"Statut pr√©dit: {'Non solvable' if prediction[0] == 1 else 'Solvable'}")
print(f"Probabilit√©s: [Solvable: {probabilite[0][0]:.2%}, Non solvable: {probabilite[0][1]:.2%}]")

def predict_nouveaux_clients(donnees_clients):
    try:
        # Conversion en DataFrame si n√©cessaire
        if not isinstance(donnees_clients, pd.DataFrame):
            donnees_clients = pd.DataFrame(donnees_clients)

        # Chargement des mod√®les
        modele_logistique = joblib.load('log_model.joblib')
        modele_knn = joblib.load('knn.joblib')

        # Pr√©traitement
        donnees_prep = preparer_donnees(donnees_clients)

        # Pr√©dictions
        predictions = {
            'logistique': modele_logistique.predict(donnees_prep),
            'knn': modele_knn.predict(donnees_prep)
        }

        # Probabilit√©s
        probabilites = {
            'logistique': modele_logistique.predict_proba(donnees_prep),
            'knn': modele_knn.predict_proba(donnees_prep)
        }

        # Formatage des r√©sultats
        resultats = donnees_clients.copy()
        for model_name in ['logistique', 'knn']:
            resultats[f'Statut_{model_name}'] = [
                'Non solvable' if p == 1 else 'Solvable' for p in predictions[model_name]]
            resultats[f'Prob_NonSolvable_{model_name}'] = [
                f"{p[1]:.1%}" for p in probabilites[model_name]]

        return resultats

    except Exception as e:
        print(f"Erreur lors de la pr√©diction: {e}")
        return None

# Exemple d'utilisation
donnees_test = {
    'Age': [45, 26, 35],
    'Marital': [1, 3, 2],
    'Expenses': [200, 150, 180],
    'Income': [800, 650, 750],
    'Amount': [1000, 1600, 1200],
    'Prices': [1000, 1600, 1300]
}

resultats = predict_nouveaux_clients(donnees_test)
if resultats is not None:
    print("\nPr√©dictions termin√©es avec succ√®s:")
    display(resultats)

import joblib
from datetime import datetime

# Sauvegarde des mod√®les avec timestamp
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# Sauvegarde du mod√®le de r√©gression logistique
joblib.dump(log_model, f'logistic_model_{timestamp}.joblib')

# Sauvegarde du meilleur mod√®le KNN
joblib.dump(best_knn, f'best_knn_model_{timestamp}.joblib')

# Sauvegarde du StandardScaler (si utilis√© pour la r√©gression logistique)
joblib.dump(scaler, f'scaler_{timestamp}.joblib')  # Remplacez 'scaler' par votre objet StandardScaler

print("Mod√®les et scaler sauvegard√©s avec succ√®s")

def load_and_predict(new_data):
    """
    Charge les mod√®les et fait des pr√©dictions sur de nouvelles donn√©es
    Args:
        new_data: DataFrame avec les colonnes ['Age', 'Marital', 'Expenses', 'Income', 'Amount', 'Price']
    Returns:
        DataFrame avec les pr√©dictions et probabilit√©s
    """
    try:
        # Charger les mod√®les (utilisez les bons chemins)
        log_model = joblib.load('logistic_model.joblib')
        best_knn = joblib.load('best_knn_model.joblib')
        scaler = joblib.load('scaler.joblib')

        # Pr√©parer les nouvelles donn√©es (identique au pr√©traitement d'entra√Ænement)
        X_new = new_data[['Age', 'Marital', 'Expenses', 'Income', 'Amount', 'Price']].copy()

        # Standardisation pour la r√©gression logistique
        X_new_scaled = scaler.transform(X_new)

        # Pr√©dictions
        log_pred = log_model.predict(X_new_scaled)
        log_proba = log_model.predict_proba(X_new_scaled)

        knn_pred = best_knn.predict(X_new)  # KNN n'utilise pas les donn√©es scaled dans votre code original
        knn_proba = best_knn.predict_proba(X_new)

        # Cr√©ation du DataFrame de r√©sultats
        results = new_data.copy()
        results['Logistic_Pred'] = ['Non solvable' if p == 1 else 'Solvable' for p in log_pred]
        results['Logistic_Proba_NonSolvable'] = [f"{p[1]:.1%}" for p in log_proba]
        results['KNN_Pred'] = ['Non solvable' if p == 1 else 'Solvable' for p in knn_pred]
        results['KNN_Proba_NonSolvable'] = [f"{p[1]:.1%}" for p in knn_proba]

        return results

    except Exception as e:
        print(f"Erreur lors de la pr√©diction: {e}")
        return None

# Nouvelles donn√©es √† pr√©dire (exemple)
new_clients = pd.DataFrame({
    'Age': [45, 30, 55],
    'Marital': [2, 1, 3],  # 1=C√©libataire, 2=Mari√©, 3=Divorc√© (selon votre encodage)
    'Expenses': [85, 73, 120],
    'Income': [150, 129, 180],
    'Amount': [1000, 800, 1500],
    'Price': [1200, 846, 1700]
})

# Faire les pr√©dictions
predictions = load_and_predict(new_clients)

# Afficher les r√©sultats
if predictions is not None:
    print("\nR√©sultats des pr√©dictions:")
    display(predictions[['Age', 'Marital', 'Logistic_Pred', 'Logistic_Proba_NonSolvable',
                       'KNN_Pred', 'KNN_Proba_NonSolvable']])

    # Sauvegarder les r√©sultats
    predictions.to_excel('predictions_new_clients.xlsx', index=False)
    print("\nR√©sultats sauvegard√©s dans 'predictions_new_clients.xlsx'")